{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image processing basics tutorial\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/17FpJs0ZGxcl_6w8uyZSt2hBhFxBtHpVy)\n",
    "\n",
    "If you have never used a Jupyter notebook before :\n",
    "- Click on Help>User Interface Tour in the above menu.\n",
    "- Basic things to know :\n",
    "    - Click on a cell to select it and be able to modify the content\n",
    "    - **Shift+Enter to execute a cell and select the next one** (Ctrl+Enter if you do not want to select the next one)\n",
    "    - The button in the toolbar allow you to easily add/remove/copy cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scikit-Image a nice easy-to-use module to process images\n",
    "import skimage\n",
    "from skimage import data, io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Module to process arrays\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Module to plot the images\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "# This command allows to plot directly on the notbook (use %matplotlib notebook if you want to interact with the image)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Images available\n",
    "* ./images/cadaster_sample.jpg (color)\n",
    "* ./images/document.jpg (grayscale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics\n",
    "\n",
    "### Load an image and show it in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the image from scikit-image and create the PNG file\n",
    "f = data.chelsea()\n",
    "io.imsave('my_image.png', f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load it and show\n",
    "image = io.imread('my_image.png')\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the shape of the image (height, width, channels)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the first channel of the image and its shape\n",
    "channel_red = image[:, :, 0]\n",
    "channel_red.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the first channel of the image (red)\n",
    "plt.imshow(channel_red, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compare the 3 channels \n",
    "channel_green = image[:,:,1]\n",
    "channel_blue = image[:,:,2]\n",
    "\n",
    "# Formatting plot\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(1,3,1)\n",
    "plt.title('Red')\n",
    "plt.imshow(channel_red, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,2)\n",
    "plt.title('Green')\n",
    "plt.imshow(channel_green, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,3)\n",
    "plt.title('Blue')\n",
    "plt.imshow(channel_blue, cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A color pixel has 3 values corresponding to the 3 channels. When decomposing the image into channels, we can see which are the principal colors. A high value (towards white) means an important contribution of the color component to the image and a low value (toward black) means few contibution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert a color image to grayscale image\n",
    "grayscale_image = color.rgb2gray(image)\n",
    "plt.imshow(grayscale_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image as an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can access the pixels of the image by knowing its row and column \n",
    "# /!\\ In Python, indexing starts at 0 (so first pixel is 0)\n",
    "# Get the pixel in the 5th row and 7th column\n",
    "pixel = image[4, 6, :]\n",
    "pixel \n",
    "# The 3 values correspond to the R G and B channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually pixels are represented as unsigned integers between 0 and 255 (256 values encoded in 8 bits (2^8=256)), we say they have uint8 type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Crop the image from row 81 to 150 and from column 131 to 220 \n",
    "# /!\\ In Python, the end index is not included so the crop is between [80,150[ and [130,220[\n",
    "crop = image[80:150, 130:220, :]\n",
    "plt.imshow(crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crop.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rescale image by a factor 2\n",
    "rescaled_image = transform.rescale(image, scale=2, mode='constant')\n",
    "plt.imshow(rescaled_image)\n",
    "rescaled_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Resize image to have a square size\n",
    "resized_image = transform.resize(image, (200,200), mode='constant')\n",
    "plt.imshow(resized_image)\n",
    "resized_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rotate image by 90Â° counter-clockwise\n",
    "rotated_image = transform.rotate(image, 90, resize=True)\n",
    "plt.imshow(rotated_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution\n",
    "\n",
    "Convolution is usually very much linked with filtering, and a convolution kernel is usually called a convolution filter.\n",
    "\n",
    "In this section, we have you experiment with different kernels (filters). It is a low-level operation (in the visual processing sense), as an end-user you usually do not need this, but it is good to build the intuition.\n",
    "\n",
    "First example is a local averaging filter, which can be seen at the basis of local response normalization system.\n",
    "\n",
    "Second and third examples are edge detectors, which we know are encoded in human cells.\n",
    "\n",
    "Finally, we show that a filter can also work differently for the channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function to plot the convolution kernels\n",
    "def plot_kernel(X,Y,Z):\n",
    "    fig = plt.figure()\n",
    "    # Plot 2D kernel\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ker = ax.imshow(Z, cmap='gray')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.colorbar(ker, shrink=0.5, aspect=5)\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Plot the surface\n",
    "    ax = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "    surf = ax.plot_surface(X, Y, Z, cmap='coolwarm', linewidth=0, antialiased=False)\n",
    "    fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian filter (Blur)\n",
    "https://en.wikipedia.org/wiki/Gaussian_function#Multi-dimensional_Gaussian_function\n",
    "\n",
    "A Gaussian filter is a local average of the intensity, effectively blurring the image. It is the most common low-pass filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.arange(-3, 3, 0.2)\n",
    "Y = np.arange(-3, 3, 0.2)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z = (10/np.sqrt(2*np.pi)*np.exp(-(X**2/2)-(Y**2/2)))\n",
    "\n",
    "plot_kernel(X,Y,Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blurred_image = filters.gaussian(image, 5, multichannel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(blurred_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge detection (Sobel)\n",
    "https://en.wikipedia.org/wiki/Sobel_operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sobel kernel\n",
    "sobel_kernel_x = np.array([[-1, 0, 1], [-2, 0, 2],[-1, 0, 1]], dtype=np.float32)\n",
    "sobel_kernel_y = np.array([[-1, -2, -1],[0, 0, 0],[1, 2, 1]], dtype=np.float32)\n",
    "\n",
    "# Plot filter kernels\n",
    "X = np.arange(-3, 3, 0.2)\n",
    "Y = np.arange(-3, 3, 0.2)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z = np.repeat(np.repeat(sobel_kernel_y, 10, axis=0), 10, axis=1)\n",
    "plot_kernel(X,Y,Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sobel H and Sobel V (also know as Sobel Y and Sobel X) find edges in horizontal and vertical directions\n",
    "sobel_h = filters.sobel_h(grayscale_image)\n",
    "sobel_v = filters.sobel_v(grayscale_image)\n",
    "sobel = filters.sobel(grayscale_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Formatting plot\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(1,3,1)\n",
    "plt.title('sobel x')\n",
    "plt.imshow(sobel_v, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,2)\n",
    "plt.title('sobel y')\n",
    "plt.imshow(sobel_h, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,3)\n",
    "plt.title('combined')\n",
    "plt.imshow(sobel, cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gabor filter\n",
    "https://en.wikipedia.org/wiki/Gabor_filter\n",
    "\n",
    "The gabor filter is a more complex edge-like feature. It is believed to be an accurate model of the first step of the first part of the visual processing in the brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,7))\n",
    "for i, angle in enumerate([0, np.pi/8, np.pi/4, np.pi/2, 3*np.pi/4, 7*np.pi/8]):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    image_gabor = filters.gabor_kernel(frequency=0.2, theta=angle)\n",
    "    plt.title('Angle={:.02f}'.format(angle))\n",
    "    plt.imshow(np.real(image_gabor), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,7))\n",
    "for i, angle in enumerate([0, np.pi/8, np.pi/4, np.pi/2, 3*np.pi/4, 7*np.pi/8]):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    image_gabor = filters.gabor(grayscale_image, frequency=0.2, theta=angle)\n",
    "    plt.title('Angle={:.02f}'.format(angle))\n",
    "    plt.imshow(image_gabor[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Conversion as a filter\n",
    "\n",
    "The previous examples were showing spatial filters that all operate the same for the R-G-B channels. But that does not have to be the case. Here we try the opposite where a our filter, just look at one pixel but process the R-G-B information differently.\n",
    "\n",
    "The Luminance-Chrominance decomposition of a color for instance https://en.wikipedia.org/wiki/YCbCr is a linear combination of the R-G-B signals.\n",
    "\n",
    "In this case, each of the 3 filters (Y,Cb,Cr) uses the 3 input channels (R,G,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Composition weights | RED , GREEN , BLUE |\n",
    "Y_weights = np.array([0.299, 0.514, 0.114])\n",
    "Cb_weights = np.array([-0.168736, -0.331264, 0.5])\n",
    "Cr_weights = np.array([0.5, -0.418688, -0.081312])\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,3,1)\n",
    "plt.title(\"Luminance\")\n",
    "plt.imshow(image @ Y_weights, cmap='gray')\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"Chrominance Blue\")\n",
    "plt.imshow(image @ Cb_weights, cmap='gray')\n",
    "plt.colorbar(shrink=0.4)\n",
    "plt.subplot(1,3,3)\n",
    "plt.title(\"Chrominance Red\")\n",
    "plt.imshow(image @ Cr_weights, cmap='gray')\n",
    "plt.colorbar(shrink=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing is not just convolution\n",
    "\n",
    "The Scikit-Image library has a lot to offer. Here we show one example with the restauration module, but feel free to look around http://scikit-image.org/docs/dev/auto_examples/\n",
    "\n",
    "### Restauration module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import restoration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = io.imread('./images/cadaster_sample.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add noise to image \n",
    "sigma = 0.155\n",
    "noisy_image = skimage.util.random_noise(image[:200,:200,:], var=sigma**2) # We take a crop of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(noisy_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_denoised = restoration.denoise_nl_means(noisy_image, patch_size=7, patch_distance=11, multichannel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(image_denoised, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = io.imread('./images/page.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add noise to image \n",
    "sigma = 0.155\n",
    "noisy_image = skimage.util.random_noise(image, var=sigma**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.imshow(noisy_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_denoised = restoration.denoise_tv_bregman(noisy_image, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.imshow(image_denoised, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
