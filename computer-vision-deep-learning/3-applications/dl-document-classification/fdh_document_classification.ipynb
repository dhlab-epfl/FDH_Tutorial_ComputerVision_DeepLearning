{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fdh-document-classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfz9ey80dOX0",
        "colab_type": "text"
      },
      "source": [
        "# Historical document classification\n",
        "We'll show with a very simple exmaple how to separate 3 different type of documents using a simple convolutional neural network.\n",
        "\n",
        "**Don't forget to turn on the GPU for the training** Runtime > Change runtime type > Hardware accelerator > GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz82_Vfkl-Ck",
        "colab_type": "text"
      },
      "source": [
        "## Downloads"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0bKxY2uNyv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/dhlab-epfl/fdh-tutorials/releases/download/v0.1/data_classification.zip -O /content/data_classification.zip\n",
        "!rm -r /content/data_classification;unzip /content/data_classification.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "542yNVMUmTCX",
        "colab_type": "text"
      },
      "source": [
        "## Data preparation\n",
        "This part is adapted from the [example](https://www.tensorflow.org/tutorials/load_data/images#basic_methods_for_training) of data preparation in Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTeh9tnvPRN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install TensorFlow\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from glob import glob \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1DweaUfOB1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_dir = '/content/data_classification/test'\n",
        "train_data_dir ='/content/data_classification/train'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iHeQfsmSMFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# count number of sample for each split\n",
        "n_train = len(glob(os.path.join(train_data_dir, '*', '*')))\n",
        "n_test = len(glob(os.path.join(test_data_dir, '*', '*')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTyqTDa6qCGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_train, n_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AzkXWN_OJ9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CLASS_NAMES = [os.path.basename(d) for d in glob(os.path.join(train_data_dir, '*'))]\n",
        "BATCH_SIZE = 64\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "IMG_WIDTH = 200\n",
        "IMG_HEIGHT = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz-DEVwvpHzg",
        "colab_type": "text"
      },
      "source": [
        "There are 3 classes :\n",
        "* illustration\n",
        "* sale information\n",
        "* objects description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfD4WNTEOlUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CLASS_NAMES"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKtfNB5ROmQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, '/')\n",
        "  # The second to last is the class-directory\n",
        "  return parts[-2] == CLASS_NAMES\n",
        "\n",
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  # resize the image to the desired size.\n",
        "  return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
        "\n",
        "def process_path(file_path):\n",
        "    label = get_label(file_path)\n",
        "    # load the raw data from the file as a string\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = decode_img(img)\n",
        "    return img, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUAIaKMEwSxj",
        "colab_type": "text"
      },
      "source": [
        "Prepare the data for the training, this means:\n",
        "* Load the images\n",
        "* Resize the images to 200 x 200\n",
        "* Associate the correct label to each image\n",
        "\n",
        "We will use for that the TensorFlow ``Dataset`` object. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG4lDA-QO8Qo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a Dataset object with all the image filenames\n",
        "list_ds_train = tf.data.Dataset.list_files(os.path.join(train_data_dir, '*', '*'))\n",
        "list_ds_test = tf.data.Dataset.list_files(os.path.join(test_data_dir, '*', '*'))\n",
        "\n",
        "# Load, resize and couple\n",
        "labeled_ds_train = list_ds_train.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "labeled_ds_test = list_ds_test.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPX8xXaPor3S",
        "colab_type": "text"
      },
      "source": [
        "Show one example per class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMt4MEp4sRH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id_label_list = [0, 1, 2]\n",
        "i = 1\n",
        "plt.figure(figsize=(20,50))\n",
        "while id_label_list:\n",
        "  image, label = list(labeled_ds_train.take(1))[0]\n",
        "  label_id = np.argmax(label.numpy())\n",
        "  if label_id in id_label_list:\n",
        "    plt.subplot(1, 3, i)\n",
        "    plt.imshow(image.numpy())\n",
        "    plt.title(CLASS_NAMES[label_id])\n",
        "    plt.axis('off')\n",
        "    id_label_list.remove(label_id)\n",
        "    i += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__NH9zPlyCmW",
        "colab_type": "text"
      },
      "source": [
        "Batch data for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USUIkG7MP47H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = labeled_ds_train.shuffle(buffer_size=1000).repeat().batch(BATCH_SIZE, drop_remainder=True).prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = labeled_ds_train.repeat().batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_PuWOwImWET",
        "colab_type": "text"
      },
      "source": [
        "## Model definition\n",
        "We will use a simpel convolutional model, you can play with the filter numbers, the number of layers, etc, and see the effect on the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZfWtT_uQk4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu'),\n",
        "  tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(len(CLASS_NAMES), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS3jUTKJmZgL",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEH7u2sRQk7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(train_ds,\n",
        "          validation_data=test_ds,\n",
        "          steps_per_epoch=n_train // BATCH_SIZE,\n",
        "          validation_steps=n_test // BATCH_SIZE,\n",
        "          epochs=5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRzRdbqdyY33",
        "colab_type": "text"
      },
      "source": [
        "## Visualize prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUlYgyQXzReS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Take one sample from the test dataset\n",
        "image_to_predict = list(labeled_ds_test.take(1))[0][0].numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUuL8PAFVO-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(image_to_predict[None])\n",
        "label = CLASS_NAMES[np.argmax(predictions)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bpJZLdfV0nb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(image_to_predict)\n",
        "plt.title(label)\n",
        "plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}