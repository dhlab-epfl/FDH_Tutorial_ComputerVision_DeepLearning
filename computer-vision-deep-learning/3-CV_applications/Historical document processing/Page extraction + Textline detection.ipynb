{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historical document : page and line extraction\n",
    "\n",
    "In this tutorial you will use the _dhSegment_ package, which is a tool for segmentation of historical documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from skimage import io\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this notebook, you need to install the dhSegment package.\n",
    "\n",
    "`pip install git+https://github.com/dhlab-epfl/dhSegment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dh_segment\n",
    "from dh_segment.inference import LoadedModel\n",
    "from dh_segment.io import PAGE\n",
    "from dh_segment.post_processing import thresholding, cleaning_binary, cleaning_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading pre-trained models\n",
    "\n",
    "The models that you will use were already trained (on the READ-BAD dataset), so you'll have to donwload them\n",
    "\n",
    "Download and unzip `model.zip` from https://github.com/dhlab-epfl/dhSegment/releases/tag/v0.2 for a page extraction mdoel.\n",
    "\n",
    "Download and unzip `line_model.zip` from https://github.com/dhlab-epfl/FDH_Tutorial_ComputerVision_DeepLearning/releases for a texline extraction model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to load each model in a separated session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess1 = tf.InteractiveSession()\n",
    "with sess1.graph.as_default():\n",
    "    model_page = LoadedModel(\"model/\")\n",
    "    \n",
    "sess2 = tf.InteractiveSession(graph=tf.Graph()) # New Graph need to be initialized in the session 2\n",
    "with sess2.graph.as_default():\n",
    "    model_textline = LoadedModel(\"polylines/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and show the image that will be processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filename = \"images/0167.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = io.imread(image_filename)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Page extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll feed the image to the network. \n",
    "\n",
    "__WARNING__ : This step may take a few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_page = model_page.predict(image_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `predict` method returns a dictionary with keys : \n",
    "* `probs` : the probability maps\n",
    "* `original_shape` : the shape of the original image\n",
    "* `labels` : the labels (the binary prediction, i.e thresholded `probs`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability maps that is of interest for us in in the channel 1 (`output_page['probs'][0,:,:,1]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_probs = output_page['probs'][0,:,:,1]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(page_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page map probabilty post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to threshold the probabilities to obtain a binary image (`thresholding`) and then the binary image is cleaned in order to remove small elements (`cleaning_binary`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need to obtain the coordinates of the page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_mask = thresholding(page_probs, threshold=0.7)\n",
    "page_mask = cleaning_binary(page_mask, kernel_size=7).astype(np.uint8)*255\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(page_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find and save the coordinates of the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dh_segment.post_processing import boxes_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_coords = boxes_detection.find_boxes(resize(page_mask, img.shape[:2]).astype(np.uint8), n_max_boxes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PAGE.Pag`e object is a class representing a historical document page with its `TextRegion`s, `TextLine`s, `Border`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAGE_info = PAGE.Page(image_width=img.shape[1], image_height=img.shape[0],\n",
    "                      page_border=PAGE.Border(PAGE.Point.list_to_point(list(page_coords))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img = img.copy()\n",
    "PAGE_info.draw_page_border(plot_img, autoscale=True, fill=False, thickness=15)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(plot_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Texline detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That that we have extracted the page, we'd like to extract the text lines, so again ge call `predict` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_textline = model_textline.predict(image_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textline_probs = output_textline['probs'][0,:,:,1]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(textline_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line map probabilty post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the binary mask we extracted in the previous section to eliminate the lines belonging to the left page that were wrongly detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dh_segment.post_processing import hysteresis_thresholding\n",
    "\n",
    "textline_probs2 = cleaning_probs(textline_probs, 2)\n",
    "extracted_page_mask = np.zeros(textline_probs.shape, dtype=np.uint8)\n",
    "PAGE_info.draw_page_border(extracted_page_mask, color=(255,))\n",
    "textline_mask = hysteresis_thresholding(textline_probs2, low_threshold=0.3, high_threshold=0.6,\n",
    "                                        candidates_mask=extracted_page_mask>0\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(textline_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the lines, vectorize and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dh_segment.post_processing import line_vectorization\n",
    "\n",
    "lines = line_vectorization.find_lines(resize(textline_mask, img.shape[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `Page` structure, `TextLines` are always contained in `TextRegion` object, so first we create a `TextRegion` object which `TextLines` are the ones we just extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_region = PAGE.TextRegion()\n",
    "text_region.text_lines = [PAGE.TextLine.from_array(line) for line in lines]\n",
    "PAGE_info.text_regions.append(text_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img = img.copy()\n",
    "PAGE_info.draw_page_border(plot_img, autoscale=True, fill=False, thickness=15)\n",
    "PAGE_info.draw_lines(plot_img, autoscale=True, fill=False, thickness=15, color=(0,255,0))\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(plot_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
