{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the loading function of Scikit-Image\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the image and plotting it\n",
    "\n",
    "By now you should be familiar with this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = io.imread('face.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting faces\n",
    "\n",
    "This subpart is heavily based on the tutorial of dlib http://dlib.net/face_detector.py.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the dlib library\n",
    "import dlib\n",
    "# Load the frontal face detector\n",
    "detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the detector to the img and return the detections (the '1' is a upsampling factor to get better results, not mandatory)\n",
    "dets = detector(img, 1)\n",
    "print(\"Number of faces detected: {}\".format(len(dets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dets` is a special `dlib` structure which contains the detected rectangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the first detected face\n",
    "dets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "def draw_detection(det):\n",
    "    # gca -> get-current-axis\n",
    "    current_axis = plt.gca()\n",
    "    # Add a rectangle on top of the image with the position defined by the detected face\n",
    "    current_axis.add_patch(\n",
    "                Rectangle(\n",
    "                    (det.left(), det.top()),  # x, y\n",
    "                    det.right() - det.left(), det.bottom() - det.top(),  # w, h\n",
    "                    edgecolor=\"red\", fill=False))\n",
    "    \n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img)\n",
    "for det in dets:\n",
    "    # For each detected face, draw it\n",
    "    draw_detection(det)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what you have learned in the first session, would you be able to crop the image to get the first detected face?\n",
    "\n",
    "Remember that the image array (in numpy) is y-first, x-second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting a face descriptor\n",
    "\n",
    "This part of the tutorial is based on http://dlib.net/face_recognition.py.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shape predictor to refine the face detection result (find face landmarks like eye corners, mouth, etc...)\n",
    "sp = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "# Face recognition model\n",
    "facerec = dlib.face_recognition_model_v1('dlib_face_recognition_resnet_model_v1.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the image and detecting the only face, you should be familiar about it by now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query_img = io.imread('query.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_det = detector(query_img, 1)[0]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(query_img)\n",
    "draw_detection(query_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the landmarks/parts for the face in box d.\n",
    "query_shape = sp(query_img, query_det)\n",
    "# Extract the face descriptor\n",
    "query_face_descriptor = facerec.compute_face_descriptor(query_img, query_shape)\n",
    "query_face_descriptor = np.asarray(query_face_descriptor)  # Converting the descriptor to standard numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extracted a 128-D vector that represents the identity of the face. But for us it is just a list of numbers that does not tell us much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query_face_descriptor.shape)\n",
    "print(query_face_descriptor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face recognition\n",
    "\n",
    "The face descriptor is not useful by itself, but it is a great tool to compare the facial identity between different photographs.\n",
    "\n",
    "We have 10 faces of known personalities in the `faces` directory (you can browse the directory from the jupyter system), and we will try to compare them all with our query face.\n",
    "\n",
    "In practice, an euclidean distance between 2 descriptors smaller than 0.6 usually means that the two descriptors are from the same person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task\n",
    "\n",
    "You will need to fill some gaps using the examples above. For each image, perform the detection, extract the face feature, and compute the euclidean distance with the face feature of the query.\n",
    "\n",
    "Each output should look like this :\n",
    "\n",
    "![result](desired_result.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm  # For the eye-candy progress-bar\n",
    "\n",
    "# List all the filenames in the faces directory\n",
    "face_files = glob('faces/*')\n",
    "face_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For each file\n",
    "for filename in tqdm(face_files, 'Processing'):\n",
    "    # Read the image\n",
    "    img = io.imread(filename)\n",
    "    # Detect faces in img, and take the first detected result\n",
    "    det = None  # TODO\n",
    "    # Refine the detected face by extracting the \n",
    "    shape = None  # TODO\n",
    "    # Extract the face descriptor\n",
    "    face_descriptor = None  # TODO\n",
    "    # Compute the euclidean distance between our query face descriptor and the current one\n",
    "    dist = None  # TODO\n",
    "    # Plot the detection result\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    draw_detection(det)\n",
    "    plt.title(\"{} : distance={:.2f}\".format(filename.split('/')[-1], dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all goes well, despite the original image and the one in the 'face database' being quite different, the dlib library is quite confident about both of them coming from the same person (d<0.6).\n",
    "\n",
    "Funny thing, the second closest face descriptor comes from his father..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For the bored people, you could have a better look at the shape predictor that finds out the landmark on the face\n",
    "# A good starting point is http://dlib.net/face_landmark_detection.py.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
